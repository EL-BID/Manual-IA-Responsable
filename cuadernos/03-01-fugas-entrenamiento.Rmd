---
title: "Fugas entrenamiento-validación"
output: 
  html_document:
    theme: cerulean
    css: [ "./css/style.css"]
---

Veremos varios ejemplos de cómo las fugas de entrenamiento a validación producen estimaciones
sesgadas del desempeño de predictores.


### Caso 1: selección de variables antes de particionar



```{block2, type='resumen'}
Cualquier paso de preprocesamiento debe hacerse sin usar datos de validación. Esto incluye
métodos como validación cruzada
```


Este ejemplo es originalmente de [@ESL], y utilizaremos datos sintéticos 

```{r, message = FALSE}
library(tidyverse)
simular <- function(n = 100, p = 500){
  datos <- map(1:p, ~ rnorm(n)) %>% 
    bind_cols()
  datos$y <- rbinom(n, 1, 0.5)
  datos
}
datos_entrena <- simular(n = 200, p = 1000)
datos_prueba <- simular(n = 2000, p = 1000)
dim(datos_entrena)
datos_entrena %>% group_by(y) %>% tally()
```

Nuestra selección de variables está dada por la siguiente función. Esta función **selecciona las
variables más correlacionadas con la respuesta*. Por sí solo este método no es incorrecto, pero cuando
se ejecuta sobre los datos que se usarán en validación (validación cruzada), entonces la estimación
de desempeño es optimista:

```{r}
seleccionar <- function(datos, num_var = 10){
  correlaciones <- datos %>% 
    pivot_longer(cols = matches("V"), names_to = "variable", values_to = "x") %>% 
    group_by(variable) %>% 
    summarise(corr = abs(cor(y, x))) %>% 
    arrange(desc(corr)) 
  # seleccionar 
  seleccionadas <- correlaciones %>% 
    top_n(num_var, wt = corr) %>% 
    pull(variable)
  datos %>% select(one_of(c("y", seleccionadas)))
}

```

### Método erróneo

Para cualquier corte de validación cruzada el error parece ser menor a 0.5:

```{r}
datos_filtrados <- seleccionar(datos_entrena)
datos_filtrados
```


```{r, message = FALSE}
corte_validacion <- datos_filtrados %>% sample_frac(0.7)
valida <- anti_join(datos_filtrados, corte_validacion)
modelo_1 <- glm(y ~ ., corte_validacion, family = "binomial")
mean(as.numeric(predict(modelo_1, valida) > 0) == valida$y)
```

Sin embargo, el desempeño real del modelo será:

```{r}
mean(as.numeric(predict(modelo_1, datos_prueba) > 0) == datos_prueba$y)
```



### Método correcto

La selección de variables debe hacerse en cada vuelta de validación cruzada:

```{r, message=FALSE}
corte_validacion <- datos_entrena %>% sample_frac(0.7)
datos_filtrados_corte <- seleccionar(corte_validacion)
valida <- anti_join(datos_entrena, corte_validacion)
modelo_1 <- glm(y ~ ., datos_filtrados_corte, family = "binomial")
mean(as.numeric(predict(modelo_1, valida) > 0) == valida$y)
```

