---
title: '(Ejemplo) Herramientas de Evaluación'
subtitle: 'fAIr LAC'
output:
  html_document:
    df_print: paged
bibliography: refs.bib
---

#  {.tabset}

```{js logo-js, echo=FALSE}
$(document).ready(function() {
  $('#header').parent().prepend('<div id=\"logo\"><img src=\"logo_fAIr.jpeg\" style=\"position:absolute; top:0; right:0; padding:20px; z-index:-200; height:200px\"></div>');
  $('#header').css('margin-right', '120px')
});
```

## Introducción

Este notebook muestra la construcción del checklist y el model card para un caso ejemplo de un modelo de predicción de ingresos bajos para personas autoempleadas.

- Lista de verificación (Checklist): Herramienta que consolida las principales preocupaciones por dimensión de riesgo del ciclo de vida de IA. El checklist debe revisarse de forma continua por el equipo técnico acompañado por el tomador de decisiones.

-	Perfil de modelo (Model Card): Descripción final de un sistema de IA, reporta los principales supuestos, las características más importantes del sistema y las medidas de mitigación implementadas.



<br>
<br>
<br>
<br>

## Check-list  {#checklist}



```{block2, type='resumen1'}

**Conceptualización y diseño de políticas públicas**

&#x2611;  Definición correcta del problema y de la respuesta de política pública:  

  - (Cualitativo)¿Se definió claramente el problema de política pública que se está buscando resolver?
  - (Cualitativo) Describa cómo se da respuesta a este problema actualmente, considerando a las instituciones relacionadas y cuál es su propuesta para solucionar dicho problema usando IA.
  - (Cualitativo) ¿Se definieron las acciones o intervenciones que se realizarán a partir del resultado del sistema de Inteligencia Artificial?

&#x2611; Necesidad y proporcionalidad

  - (Cualitativo) ¿Afectará su proyecto de forma directa o indirecta a la vida de personas o de personas o grupos vulnerables?
  - (Cualitativo) Para la implementación de estas tecnologías, ¿se han revisado casos de proyectos similares anteriores?
  - (Cualitativa) ¿Se identificaron los distintos grupos o atributos protegidos dentro del proyecto? (por ejemplo: edad, género, raza, nivel de marginación, etc.)
  
**Gobernanza y seguridad**
  
&#x2611; Consentimiento informado y límites de privacidad: 
  
  - (Cuantitativa) ¿Se ha definido de forma clara la finalidad del tratamiento de los datos que va a recopilar y/o procesar?
  - (Cuantitativa) ¿Su proyecto cuenta con los acuerdos legales de transferencia de información necesarios?

&#x2611; Gobernanza y ciberseguridad 
  
  - (Cuantitativa) El Proyecto cuenta con estructuras y mecanismos concretos de gobernanza y ciberseguridad?
  - (Cuantitativa) ¿Se han considerado formas de reducir al mínimo la exposición de información personal identificable? (por ejemplo, mediante la anonimización o la no recopilación de información que no sea pertinente para el análisis)

**Fuente y manejo de datos** 

&#x2611; Calidad de datos recolectados y relevancia de variable respuesta:  

  - (Cualitativa) ¿Se ha justificado claramente la utilización de la variable respuesta seleccionada bajo los propósitos de la intervención?
  - (Cuantitativa) ¿Se han examinado los datos en busca de posibles sesgos históricos o estados indeseables que no queramos replicar?

&#x2611; Muestras naturales y diseñadas:

  - (Cualitativa) ¿Se ha analizado las posibles diferencias entre la base de datos y la población para la que se busca desarrollar el sistema de IA? (Utilizar literatura relacionada con el tema, información de expertos. Estudiar en particular sesgos de selección no medidos)

&#x2611; Atributos incompletos

  - (Cualitativa) ¿Se ha realizado un análisis de valores faltantes y de variables omitidas?
  - (Cualitativa) ¿Se ha identificado si existen variables omitidas importantes para las cuales no se tiene mediciones asociadas?
  - (Cualitativa) ¿Se ha identificado las razones por las que existen observaciones faltantes? (En caso de existir)

&#x2611; Comparación Causal

  - (Cualitativa) ¿Se manifestó de forma explícita las limitaciones de los resultados al tomador de decisiones de política pública? (En caso de que no se haya trabajado en asegurar causalidad en los resultados)
  
**Desarrollo de modelos**

&#x2611; Ausencia y errores de validación:

  - (Cuantitativa) ¿Se construyeron las muestras de validación y prueba adecuadamente?  Considerando un tamaño apropiado, cubriendo a subgrupos de interés y protegidos y evitando fugas de información durante su implementación. 
  
&#x2611; Métricas de evaluación engañosas: 

  - (Cualitativa) ¿Se cuestionaron las implicaciones de los diferentes tipos de errores para el caso de uso específico, así como la forma correcta de evaluarlos?
  - (Cualitativa) ¿Se explicó de forma clara las limitantes del modelo? Identificando tanto los falsos positivos como falsos negativos y las implicaciones que una decisión del sistema tendría en la vida de la población beneficiaria.
  - (Cuantitativa) ¿Se implementó un análisis costo-beneficio del sistema contra el status quo u otras estrategias de toma/soporte de decisión? (Cuando es posible) 

&#x2611; Errores no cuantificados y evaluación humana: 

  - (Cualitativa) Se realizó una evaluación humana con expertos del caso de uso para buscar sesgos o errores conocidos? (Por ejemplo, se pueden usar paneles de revisores que examinen predicciones particulares y consideren si son razonables o no. Estos paneles deben ser balanceados en cuanto al tipo de usuarios que se prevén, incluyendo tomadores de decisiones si es necesario).
  
&#x2611; Equidad y desempeño diferencial: 

  - (Cualitativa) ¿Se definió con expertos y tomadores de decisiones la medida de justicia algorítmica a usarse en el proyecto? 
  - (Cuantitativo) ¿Se ha comprobado la equidad de los resultados del modelo con respecto a los diferentes grupos de interés?
  
**Uso y monitoreo**

&#x2611; Degradación de desempeño:

  - (Cualitativo) ¿Existe un plan para monitorear el desempeño del modelo y la recolección de información a lo largo del tiempo?
  - (Cualitativa) ¿Se han tomado medidas para identificar y prevenir los usos no intencionados y el abuso del modelo y tenemos un plan para monitorear estos una vez que el modelo sea desplegado? 

**Rendición de cuentas**

&#x2611; Sesgos potenciales y depuración

  - (Cualitativa) ¿Se han comunicado las deficiencias, limitaciones y sesgos del modelo a las partes interesadas de manera que estos se consideren en la toma/soporte de decisiones?

&#x2611; Interpretabilidad y explicabilidad

  - (Cualitativo) ¿Se analizaron los requerimientos legales y éticos de explicabilidad e interpretabilidad necesarios para el caso de uso?
  - (Cualitativo) ¿Se discutieron los pros y contras de los algoritmos según su nivel de interpretabilidad y explicabilidad para elegir el más apropiado?
  - (Cualitativo) ¿Se han definido un plan de respuesta en caso de que algún usuario se vea perjudicado por los resultados?
  - (Cualitativo) ¿Existe algún proceso para dar explicaciones a un individuo en particular sobre por qué se tomó una decisión?

&#x2611; Transparencia y trazabilidad

  - (Cuantitativa) ¿Está bien documentado el proceso de ingesta, transformación, modelado y toma de decisión? (incluyendo fuente de datos, infraestructura y dependencias, código, métricas e interpretación de resultados)

```



## Preprocesamiento - (Model-Card)

```{r, message=FALSE, warning = FALSE}
library(tidyverse)
library(recipes)
library(themis)
library(rsample)
library(parsnip)
library(yardstick)
library(workflows)
library(tune)
library(knitr)
library(patchwork)
```

### Ingesta de datos
```{r, message=FALSE, warning = FALSE}
adult_train <- read_csv("adult.csv", col_names = FALSE)
adult_test <- read_csv("adult_test.csv", col_names = FALSE, comment = ".")
```


### Preprocesamiento
```{r, message=FALSE, warning = FALSE}
preprocesar <- function(adult){
  colnames(adult) <- c('edad', 'tipo_trabajo', 'pond', 'educacion', 
                     'educacion_num', 'estado_civil', 'ocupacion', 'relacion', 'info_racial', 'sexo', 
                     'ganancias_capital', 'perdidas_capital', 'horas_por_semana', 'pais_origen', 
                     'ingreso')
  adulto <- adult %>% 
    mutate(pais_origen = ifelse(pais_origen == "?", "Desconocido", pais_origen)) %>% 
    mutate(ocupacion = ifelse(ocupacion == "?", "Desconocido", ocupacion)) %>%
    mutate(ingreso = fct_recode(ingreso, bajo = "<=50K", alto = ">50K")) %>% 
    mutate(tipo_trabajo = ifelse(tipo_trabajo == "?", "Desconocido", tipo_trabajo)) %>% 
    mutate(bajo_auto = ifelse(str_detect(tipo_trabajo, "Self") & (ingreso == "bajo"), "bajo_auto", "otro")) %>%
    mutate(bajo_auto = as.factor(bajo_auto)) %>% 
    select(-educacion, -pond, -ingreso)
  adulto
}
adulto_entrena <- preprocesar(adult_train)
adulto_prueba <- preprocesar(adult_test)
```

```{r}
adulto_entrena
```

```{r}
adulto_entrena %>% group_by(bajo_auto) %>% 
  summarise(conteo = n())
```


### Modelo

```{r, message=FALSE, warning = FALSE}
entrena <- adulto_entrena
prueba <- adulto_prueba

receta_adulto <- recipe(bajo_auto ~  educacion_num + info_racial + sexo +
                          horas_por_semana + estado_civil , data = entrena) %>%
  prep()
entrena_prep <- juice(receta_adulto)
```

```{r}
bosque_1 <- 
  rand_forest(trees = 500, mtry = 2, mode = "classification") %>%
  set_engine("ranger") %>%
  fit(bajo_auto ~ . , data = entrena_prep)
```


```{r}
predictions_prob <- bosque_1 %>%
  predict(new_data = prueba, type = "prob") %>%
  bind_cols(prueba %>% select(bajo_auto)) %>% 
  select(.pred_bajo_auto, bajo_auto)
datos_roc <- roc_curve(predictions_prob, bajo_auto, .pred_bajo_auto)
autoplot(datos_roc)
```


```{r, message=FALSE, warning = FALSE}
predictions_prob <- predictions_prob %>%
  mutate(sexo = prueba$sexo, info_racial = prueba$info_racial) %>% 
  mutate(info_racial = as.character(info_racial)) %>% 
  mutate(info_racial = 
    fct_recode(info_racial, Other = "Amer-Indian-Eskimo", Other = "Other")) %>% 
  mutate(info_racial = as.character(info_racial))
# bootstrap
boot_metricas <- function(predictions_prob, i){
  preds_boot <- sample_frac(predictions_prob %>% group_by(sexo, info_racial), replace = T) %>% 
    ungroup
  roc_total <- roc_auc(preds_boot, bajo_auto, .pred_bajo_auto) %>% 
    mutate(grupo = "Total", atributo = "Total")
  log_perdida_total <- mn_log_loss(preds_boot, bajo_auto, .pred_bajo_auto)
  roc_grupos <- roc_auc(preds_boot %>% group_by(sexo), bajo_auto, .pred_bajo_auto) %>% 
    rename(grupo = sexo) %>% mutate(atributo = "género")
  log_perdida_grupos <- mn_log_loss(preds_boot %>% group_by(sexo), bajo_auto, .pred_bajo_auto)
  roc_grupos_2 <- roc_auc(preds_boot %>% group_by(info_racial), bajo_auto, .pred_bajo_auto) %>% 
    rename(grupo = info_racial) %>% mutate(atributo = "racial")
  log_perdida_grupos_2 <- mn_log_loss(preds_boot %>% group_by(info_racial), bajo_auto, .pred_bajo_auto)
  resumen <- bind_rows(roc_total, roc_grupos, roc_grupos_2)
  resumen$id <- i
  resumen
}
set.seed(2321)
sim_metricas <- map(1:100, ~ boot_metricas(predictions_prob, .x)) %>% 
  bind_rows
resumen <- sim_metricas %>% group_by(.metric, .estimator, grupo, atributo) %>% 
  summarise(estimador = mean(.estimate), ee = sd(.estimate)/sqrt(length(.estimate))) %>% 
  select(-.estimator) %>% ungroup

```

```{r}
ggplot(resumen %>% mutate(grupo = fct_reorder(grupo, estimador)), aes(x = grupo, y = estimador, 
  ymin = estimador - 2*ee, ymax = estimador + 2*ee, colour = atributo)) +
  geom_point() + geom_linerange() + coord_flip() +
  ylab("AUC")
```

Como medida de justicia algorítmica utilizaremos la definición de "igualdad de oportunidades" (equilibrar probablidad de estar en el grupo de interés dentro de cada grupo protegido), o misma tasa de positivos verdaderos. 

```{r}
resultado_cortes <- function(tbl_datos, cortes){
  resultado <- tbl_datos %>% 
    left_join(cortes, by = c("sexo", "info_racial")) %>% 
    mutate(recibe = .pred_bajo_auto > corte)
  resultado %>% group_by(info_racial, sexo, recibe, bajo_auto, prop_total) %>% count() %>% 
    ungroup()
}
```


```{r}
calcular_cortes_oportunidad <- function(tbl_datos, prop){
  tbl_datos %>% 
    filter(bajo_auto=="bajo_auto") %>% 
    group_by(info_racial, sexo) %>% 
    mutate(rank_p = rank(.pred_bajo_auto) / length(.pred_bajo_auto) ) %>% 
    filter(rank_p < prop) %>% 
    top_n(1, rank_p) %>% 
    unique() %>% 
    select(info_racial, sexo, corte = .pred_bajo_auto) %>% 
    mutate(prop_total = prop)
}
cortes_op <- 
  map(seq(0.01, 1, 0.01), ~ calcular_cortes_oportunidad(predictions_prob, .x))
cortes_op[[10]]
```


```{r}
resultados_conteo <- map(cortes_op, ~ resultado_cortes(predictions_prob, .x)) %>% 
  bind_rows()
```


```{r}
resumen_tvp <- resultados_conteo %>% 
  filter(bajo_auto == "bajo_auto") %>% 
  group_by(info_racial, sexo, prop_total) %>% 
  mutate(tvp = n / sum(n), total = sum(n)) %>% 
  filter(recibe == TRUE) %>% 
  mutate(ee = sqrt(tvp * (1-tvp) / total ))
resumen_tvp
```


```{r}
ggplot(resumen_tvp, aes(x = prop_total, y = tvp, colour = info_racial, 
                        group = info_racial)) +
  geom_line() + facet_wrap(~sexo)
```

Las tasas de verdaderos positivos son consistentes, como se puede comprobar
examinando algunas de ellas. Por ejemplo, si queremos una tasa de
positivos correctos el alrededor del 75%, 



```{r}
ggplot(resumen_tvp %>% filter(prop_total == 0.25), 
  aes(x = info_racial, y = tvp, 
      ymin = pmax(0, tvp - 2*ee), ymax = pmin(1, tvp + 2*ee), colour = sexo)) + 
  geom_point(position = position_dodge(width = 0.5)) + 
  geom_linerange(position = position_dodge(width = 0.5)) + 
  ylab("Tasa de verdaderos positivos") + ylim(c(0,1))
```

Y las tasas de verdaderos positivos son consistentes.  Para el punto de corte
seleccionado

```{r}
resumen_tvp %>% filter(prop_total == 0.25) %>% select()
```

```{r}
# seleccionar cortes finales según analisis costo-beneficio
cortes_finales <- cortes_op[[60]]
cortes_finales
```

```{r, message=FALSE, warning=FALSE}
costos_mat <- tibble(bajo_auto = c("bajo_auto", "bajo_auto", "otro", "otro"),
                 califica = c(TRUE, FALSE, TRUE, FALSE),
                 beneficio = c(60000 - 20000, 0, -2000, 0) - 1000)
costos <- predictions_prob %>%
  left_join(cortes_finales) %>%
  mutate(corte = ifelse(is.na(corte), 0.063, corte)) %>% # corte White Male
  mutate(califica = .pred_bajo_auto > corte) %>% 
  group_by(bajo_auto, califica) %>% 
  summarise(n = n()) %>% left_join(costos_mat)
costos <- costos %>% mutate(total = n * beneficio) %>% 
  ungroup %>% 
  left_join(predictions_prob %>% group_by(bajo_auto) %>% summarise(pob = n())) %>% 
  filter(califica == TRUE) %>% 
  mutate(cobertura = n / pob)
costos
```






## Perfil de modelo (Model-Card)

### 1. Conceptualización y diseño
#### 1.1 Información básica

  + *Personas que desarrollaron el modelo, fecha, versión, tipo*\
  Modelo de predicción de ingresos bajos para personas autoempleadas versión 0.1,  `r format(Sys.time(), '%d %B, %Y')`, construido por LFG. 

  + *Antecedentes*\
  Modelos para predecir la categoría de ingreso y estatus de autoempleo basados en datos similares 
  con los se han construido
  en varias ocasiones con diversos propósitos. En este caso particular los datos utilizados son
  un ejemplo común para ilustrar métodos de aprendizaje automático y equidad de predicciones (ver por ejemplo
  [@adult]). 


#### 1.2 Casos de uso 

  + *Casos de uso considerados durante el desarrollo*\
  El modelo predictivo de ingreso tiene como fin indentificar personas 
  autoempleadas de ingresos bajos con el fin de seleccionarlos como candidatos para un programa 
  de mejora en sus condiciones de trabajo. Este modelo será utilizado en complemento de encuestas
  operadas por terceros, que tendrán disponible una predicción de identificar con menor costo
  personas autoempleadas de ingresos bajos.

  + *Población objetivo y horizonte de predicciones*\
  La población objetivo es el total de la población de EUA (1994) mayor a 16 años y empleados en algún trabajo
  (mínimo de 1 hora a la semana) con una remuneración mínima de 100 dólares anuales. Buscamos hacer
  predicciones en 1994-1995

  + *Actores y componentes que interactuarán con los resultados*\
  El modelo será utilizado después de que un tercero levante encuestas en zonas de interés para
  producir un *scoring* de probabilidades de autoempleo de ingreso bajo. Los operadores del programa
  decidirán entonces, dependiendo de presupuesto y alcances, qué personas entrevistadas en esa encuesta
  se integrarán al programa. 

  + *Usos no considerados y advertencias relacionadas*\
  Recomendamos no usar esté modelo más allá del periodo 1995-1996. Las probabilidades no 
  son indicadoras de mayores o menores ingresos. 


### 2. Gobernanza y Seguridad
### 3. Fuente y manejo de datos
#### 3.1 Datos de entrenamiento

  + *Conjuntos de datos usados y su etiquetado*\
  Los datos utilizados para seleccionar y evaluar el modelo fueron
  extraidos aleatoriamente (mismas probabilidades) de los datos
  del censo de Estados Unidos (1994, agregar referencia). Se descartaron
  6 registros con datos inconsistentes (valores fuera de rango). \
  En total se escogieron 16281 casos para la evaluación, y alrededor
  del 7.6% están en la categoria de autoempleo con ingresos bajos.
  
  + *Sesgos y deficiencias potenciales según el caso de uso*\

  + *Pasos de preprocesamiento*\
  En el preprocesamiento se codificaron los valores faltantes de
  variables categóricas con "Desconocido"- El ingreso reportado se
  cortó en más de 50 mil y menos de 50 mil dólares al año. La variable de
  autoempleo fue extraída directamente de los datos reportados en el censo.
  

### 4. Desarrollo de Modelo
#### 4.1 Modelación

  + *Algoritmos que se usaron para entrenar, parámetros supuestos o restricciones*\
  Se utilizó un bosque aleatorio construido con *ranger* 0.12.1 de R.


#### 4.2 Métricas de desempeño

  + *Métricas técnicas usadas para seleccionar y evaluar modelos*\
  Las métricas usadas para la selección de modelos fue el AUC, 
  que considera las probablidades de
  estar en la categoría de autoempleo con bajos ingresos. 
  Consideramos como atributos
  protegidos *sexo* e *info_racial*

  + *Análisis costo-beneficio del modelo para su caso de uso según (2)*\
  Supondremos los siguientes parámetros para el análisis
  costo-beneficio:
    + Cada aplicación del cuestionario de focalización tiene un costo de 1500
    + Cada aplicación del programa requiere una inversión total de 20000.
    + Se estima que el beneficio del programa a los que aplican es de 60000
    + Los falsos positivos deberán ser filtrados posteriormente de manera manual. El costo administrativo de cada asignación errónea es de 2000

  + *Definición de grupos protegidos*\
  Los grupos protegidos definidos fueron: Raza y género
  
  + *Medidas de equidad seleccionadas*\
  La definición de justicia algorítmica que se utilizará es equidad de oportunidades (igualar tasas de aceptación entre aquellos que califican al programa).

#### 4.3 Datos de validación

  + *Conjunto de datos usados y su etiquetado*\
  + *Pasos de preprocesamiento*\
  El mismo proceso se utilizó para los datos de entrenamiento, 
con un total de 32561 casos y 7.1% con autoempleo de ingresos bajos.

  + *Evaluación de adaptación de datos de validación según el caso de uso (2)*\
    **No se utilizaron los ponderadores de la muestra de evaluación**. Estos ponderadores están basados en sexo, edad, estado y raza. Sin embargo,
    reportamos errores individuales para sexo y raza.

#### 4.4 Resumen de análisis cuantitativo
  + *Error de validación reportado*\
  El auc del modelo seleccionado, en el conjunto de prueba y sin ecualización de oportunidad, fue de

```{r}
autoplot(datos_roc)
```

  + *Reporte de medidas de equidad para grupos protegidos*\
  Aunque encontramos diferencias importantes en el desempeño dependiendo
  de atributos protegidos:

```{r}
resumen %>% knitr::kable(digits = 3)
```

  Las tasas de verdaderos positivos para grupos protegidos son consistentes:

```{r}
ggplot(resumen_tvp %>% filter(prop_total == 0.6), 
  aes(x = info_racial, y = tvp, 
      ymin = pmax(0, tvp - 2*ee), ymax = pmin(1, tvp + 2*ee), colour = sexo)) + 
  geom_point(position = position_dodge(width = 0.5)) + 
  geom_linerange(position = position_dodge(width = 0.5)) + 
  ylab("Tasa de verdaderos positivos") + ylim(c(0,1))
```

  + *Resumen de análisis costo-beneficio*\
  En cuanto al costo beneficio, utilizamos los puntos de corte

```{r}
cortes_finales %>% select(-prop_total)
```

  Esto implica que esperamos una proporción de alrededor de 5 a 1 de falsos positivos vs falsos negativos, una cobertura de 40% de los individuos de interés, y un costo total de 

```{r}
costos
```

  Y el beneficio total por beneficiario del programa es de:

```{r, message=FALSE, warning=FALSE}
costos %>% 
  summarise(beneficio_total = sum(total) / first(n))
```

### 5. Uso y monitoreo
#### 5.1 Recomendaciones de monitoreo
  + *Estrategia de monitoreo y mejora en producción*\
  Monitorear la tasa de personas que califica (positivos) en el tiempo, pues
  cambios en inflación e ingreso en el tiempo pueden requerir ajuste de puntos de corte.
  + *Estrategias de monitoreo humano de predicciones (si aplica)*\
  Considerar sobremuestras en los datos de grupos minoritarios, que puede
  dar más certidumbre acerca de la equidad de oportunidad en las predicciones.


### 6. Impacto sistémico
### 7. Rendición de cuentas
#### 7.1 Explicabilidad de predicciones
  Valores de Shapley serán usados si los beneficiarios requieren explicación
  del estado de solicitud. Es posible incluir la revisión humana para 
  aceptar una solicitud, pero **deberá ser contabilizado en los costos**.




# References