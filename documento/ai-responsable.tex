% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={AI responsable},
  pdfauthor={Felipe González, Teresa Ortiz, Roberto Sánchez},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}

\renewcommand{\contentsname}{Contenido}
\renewcommand{\chaptername}{Sección}
\renewcommand\bibname{Referencias}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
\fi

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\makeatletter
\@ifundefined{Shaded}{
}{\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}}
\makeatother

\newenvironment{rmdblock}[1]
  {
  \begin{itemize}
  \renewcommand{\labelitemi}{
    \raisebox{-.7\height}[0pt][0pt]{
      {\setkeys{Gin}{width=3em,keepaspectratio}\includegraphics{images/#1}}
    }
  }
  \setlength{\fboxsep}{1em}
  \begin{kframe}
  \item
  }
  {
  \end{kframe}
  \end{itemize}
  }
\newenvironment{rmdpunto}
  {\begin{rmdblock}{punto}}
  {\end{rmdblock}}
\newenvironment{rmdnote}
  {\begin{rmdblock}{note1}}
  {\end{rmdblock}}
\newenvironment{rmdcaution}
  {\begin{rmdblock}{caution}}
  {\end{rmdblock}}
\newenvironment{rmdimportant}
  {\begin{rmdblock}{important}}
  {\end{rmdblock}}
\newenvironment{rmdtip}
  {\begin{rmdblock}{manot}}
  {\end{rmdblock}}
\newenvironment{rmdwarning}
  {\begin{rmdblock}{warning}}
  {\end{rmdblock}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\frontmatter
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{AI responsable}
\author{Felipe González, Teresa Ortiz, Roberto Sánchez}
\date{2020-04-26}

\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}
\frontmatter
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\mainmatter
\hypertarget{acerca-de-este-material}{%
\chapter{Acerca de este material}\label{acerca-de-este-material}}

Este material es reproducible según instrucciones en \href{https://github.com/felipegonzalez/ai-responsable}{este repositorio}.

\mainmatter

\hypertarget{intro}{%
\chapter{Introducción}\label{intro}}

Los métodos de aprendizaje de máquina e inteligencia artificial (ML/IA), que para resumir
en este documento llamamos \textbf{aprendizaje automático} son cada vez más requeridos
y utilizados por tomadores de decisiones para informar acciones o intervenciones en varios contextos,
desde negocios hasta política pública. En la práctica, estos métodos se han utilizado con diversos
grados de éxito, y con esto ha aparecido la preocupación creciente de cómo entender
el desempeño o influencia positiva o negativa de estos métodos en el contexto de la toma de decisiones (\citep{Suresh}, \citep{barocas}).

\BeginKnitrBlock{rmdpunto}
¿Cuándo estos métodos de aprendizaje automático nos llevan a tomar decisiones que son costosas, riesgosas o pueden inducir estados
no deseados (por ejemplo, discriminatorios o injustos) en los sistemas y decisiones en donde se utilizan?
\EndKnitrBlock{rmdpunto}

\hypertarget{ia-y-toma-de-decisiones}{%
\section{IA y toma de decisiones}\label{ia-y-toma-de-decisiones}}

En este documento pretendemos discutir los problemas más comunes en el uso de ML/IA para la
toma decisiones, cómo detectar problemas potenciales y evaluar la posiblidad de resultados indeseables
para los tomadores de decisiones, para la sociedad o una compañía o institución particular. Consideramos
dos arquetipos de inclusión de aprendizaje automático en el proceso de toma de decisiones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Las decisiones se toman automáticamente, sin intervención humana directa.}
  Por ejemplo, inclusión de individuos en programas sociales, o otorgamiento de créditos al consumo.
\item
  \textbf{Resultados del aprendizaje automático son insumos para decisiones que se toman de forma más tradicional.} Por ejemplo, decisiones acerca del funcionamiento o refinación de un programa social, pronósticos
  de variables clave para planeación.
\end{enumerate}

El primer punto que tenemos que tener presente y es guía de este documento es
en la construcción y métodos particulares de los sistemas de aprendizaje automático existe una gran variedad de técnicas, conocimiento experto del tema y de modelación en general, y \textbf{en este documento} no pretendemos definir cómo deben ser esos procedimientos. En lugar de eso

\BeginKnitrBlock{rmdpunto}
\textbf{Principio guía 1}

\begin{itemize}
\tightlist
\item
  Nos concentramos en la \textbf{evaluación} de estos sistemas, antes y después de poner
  en producción o utilizar para tomar decisiones.
\item
  La evaluación sólo tiene sentido en términos del contexto de la decisión, y de los
  \textbf{resultados que son deseables para los tomadores de decisiones}, instituciones o compañías involucradas.
\end{itemize}
\EndKnitrBlock{rmdpunto}

La evaluación de un sistema de aprendizaje no tiene sentido fuera de su contexto: qué es una tasa
de error apropiado, cuáles son sesgos poco aceptables, y así sucesivamente, sólo pueden considerarse
dentro de los propósitos de los tomadores decisiones. Esto quiere decir que
aunque mucha de la discusión se concentra en
discusiones técnicas, métricas particulares de desempeño o métodos de ML, al final
ninguna de estas discusiones tiene sentido fuera del contexto de la \textbf{decisión} que
se quiere tomar, ya sea una decisión automatizada totalmente o como insumo de una decisión
tomada por páneles de expertos o tomadores de decisiones.

\hypertarget{las-tres-componentes-de-la-aplicaciuxf3n-de-mlai}{%
\section{Las tres componentes de la aplicación de ML/AI}\label{las-tres-componentes-de-la-aplicaciuxf3n-de-mlai}}

Las decisiones que consideramos tienen tres partes importantes: se considera
alguna \textbf{intervención} que se
planea aplicar personas, unidades o procesos. Esta intervención se pretende utilizar en ciertos casos
que \textbf{dependen de variables desconocidas}. Usamos aprendizaje automático para \textbf{predecir o estimar} estas variables desconocidas.

Nuestra pregunta es entonces cómo la calidad o tipo de predicciones o estimaciones pueden
influir en la focalización, y más adelante, en el resultado global de la intervención.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  (\textbf{Intervención}) Tenemos una intervención o política o intervención que estamos considerando aplicar a ciertas
  personas, unidades o procesos. Supondremos generalmente que tenemos alguna idea del beneficio de esa política cuando se aplica a distintos sectores de la población objetivo.
\item
  (\textbf{Focalización}) Esta intervención o política pretende focalizarse en ciertas unidades o circunstancias para mejorar resultados o uso de recursos.
\item
  (\textbf{Predicción o Estimación}) La focalización depende de algunas características desconocidas de las personas, unidades o procesos. Utilizamos entonces predicciones o estimaciones basadas en métodos de ML/AI para informar variables desconocidas y mejorar la focalización.
\end{enumerate}

Ejemplos de esto puede ser:

\begin{itemize}
\tightlist
\item
  Predicción del desempeño de alumnos en un sistema educativo (unidad individuo)
\item
  Predicción de ingresos trimestrales para hogares (unidad hogar)
\item
  Predicción de eventos riesgosos, por ejemplo actividad criminal (unidad zona geográfica)
\item
  Predicción de qué documentos o artículos serían útiles sugerir dada una búsqueda (unidad
  usuario-búsqueda)
\end{itemize}

\BeginKnitrBlock{rmdpunto}
\textbf{Principio guía 2}

En este documento, nos concentramos en la parte de \textbf{predicción o estimación}, y cómo deficiencias o lagunas en el proceso
de validación puede producir resultados indeseables de \textbf{focalización}
\EndKnitrBlock{rmdpunto}

\pagebreak

\hypertarget{los-retos-de-la-aplicaciuxf3n}{%
\section{Los retos de la aplicación}\label{los-retos-de-la-aplicaciuxf3n}}

En estos tres casos, examinaremos los problemas más comunes, diagnósticos para detectarlos, y sugerencias
para mitigarlos, divididos en cuatro secciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Intrínsecos a los datos}: que se refieren principalmente a deficiencias, sesgos y proceso que genera los datos utilizados \citep{biasdata}. Este es un punto de bloqueo para muchas aplicaciones.
\item
  \textbf{Relativos a la construcción y desarrollo de los modelos}: que se refiere a métodos y principios importantes para construir modelos robustos y validados correctamente.
\item
  \textbf{Relativos a la evaluación y monitoreo del modelo}: que se refiere a la interpretación del modelo, evaluación una vez puesta en producción y principios de monitoreo para evitar consecuencias inesperadas.
\item
  \textbf{Rendición de cuentas}, que se refiere al entendimiento o la capacidad de explicar
  cómo es que métodos automatizados toman ciertas decisiones.
\end{enumerate}

\hypertarget{retos-intruxednsecos-a-los-datos}{%
\chapter{Retos intrínsecos a los datos}\label{retos-intruxednsecos-a-los-datos}}

El primer conjunto de retos que tratamos son los que tienen qué ver
con los datos disponibles para aplicar métodos de aprendizaje automático.
Estos se pueden separar en dos grandes partes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calidad y relevancia de las métricas recolectadas
\item
  Información incompleta acerca de la población objetivo
\end{enumerate}

\hypertarget{muxe9tricas-introducciuxf3n}{%
\section{Métricas: introducción}\label{muxe9tricas-introducciuxf3n}}

En primer lugar, debemos considerar qué tipo de mediciones tenemos a nuestra
disposición para aplicar métodos cuantitativos, incluyendo aprendizaje automático, y cuáles
son las mediciones ideales para la decisión que se considera tomar.

\hypertarget{tuxe9rminos}{%
\subsubsection*{Términos}\label{tuxe9rminos}}


\begin{itemize}
\tightlist
\item
  \textbf{Métrica objetivo}: medición que se considera ideal para tomar la decisión relevante.
  En la medición, ese ideal es tipicamente solo alcanzando en parte.
\end{itemize}

\BeginKnitrBlock{rmdnote}
\textbf{Reto: mala correspondencia de métrica y objetivos}

\begin{itemize}
\item
  Las variables medidas corresponden pobremente a las métricas objetivo de interés, quizá con
  sesgos sistemáticos que vayan en contra de objetivos de la política.
\item
  En particular, las variables medidas contienen sesgos indeseables en términos de los objetivos de la política
\end{itemize}
\EndKnitrBlock{rmdnote}

\hypertarget{ejemplos}{%
\subsubsection*{Ejemplos}\label{ejemplos}}


\begin{itemize}
\item
  Supongamos que una política se considera aplicar a personas de ingresos bajos. Nuestro conjunto de datos de entrenamiento/validación usamos una medición obtenida en una encuesta,
  según la pregunta, \emph{¿cuánto estima usted que es el ingreso mensual de su familia?}, o algo similar.
  Esta medición está sujeta a sesgos desconocidos, y existen incentivos para ocultar fuentes de ingresos
  por parte de los participantes. Predictores de ingreso construidos con estos datos tienen el riesgo
  de replicar el sesgo de las mediciones, afectando negativamente los resultados de la asignación de la intervención.
\item
  Consideramos pronosticar los niveles de demanda de medicamentos, de manera que pueda satisfacerse la demanda adecuadamente sin incurrir en inventario que caduca. Utilizamos el
  \emph{número de unidades que fueron requeridas en el sistema} para el medicamento X. Esta no es una medida
  exacta de la demanda, porque puede ser que cuando los inventarios se agotan, los involucrados dejan de hacer requerimientos a los abastecedores. Pronosticar la demanda con estos datos puede incurrir en
  subeestimación, con el resultado de que reforzamos o empeoramos la escasez de medicamentos.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: mala correspondencia de métricas y objetivos}

\begin{itemize}
\item
  (Cualitativa) Las métricas objetivo deben plantearse claramente, aunque sean ideales. Las métricas
  recogidas deben ser analizadas para entender qué tan adecuadas son para sustituir la métrica objetivo.
  Se deben identificar sesgos sistemáticos o validez pobre de la métrica sustituto.
\item
  (Cuantitativa) Estudios adicionales diseñados para capturar métrica objetivo y métrica seleccionada permiten comparar las dos, y entender si hay sesgos que corregir y con qué variables puede lograrse esto.
\end{itemize}
\EndKnitrBlock{rmdtip}

\hypertarget{ejemplos-1}{%
\subsubsection*{Ejemplos}\label{ejemplos-1}}


\begin{itemize}
\tightlist
\item
  En la estimación de ingreso, generalmente se utilizan fuentes de datos oficiales con
  metodología bien establecida para estimar el ingreso de un hogar. Tal metodología
  debe ser sostenida por validaciones de distinto tipo que muestra posibles sesgos en la medición y de ser posible cuantificaciones del error de medición.
\item
  Para los pronósticos de demanda, es posible que sea necesario identificar fuentes adicionales
  de datos que indiquen mejor la demanda, ya sea con estudios indirectos (fuentes de datos de los compradores) o
  construyendo experimentos que nos permitan observar la demanda en ciertas unidades.
\end{itemize}

\hypertarget{informaciuxf3n-incompleta}{%
\section{Información incompleta}\label{informaciuxf3n-incompleta}}

Cuando buscamos aplicara un método del aprendizaje automático en nuestro contexto,
la información puede ser incompleta de distintas maneras:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Solo tenemos datos para una muestra de una población.
\item
  No tenemos todas las mediciones importantes para la toma de decisiones.
\item
  Tenemos datos del pasado y presente, pero no del futuro, que es cuando
  tenemos qué tomar decisiones.
\end{enumerate}

\hypertarget{muestras-naturales-y-diseuxf1adas}{%
\section{Muestras naturales y diseñadas}\label{muestras-naturales-y-diseuxf1adas}}

Nuestros modelos pretenden ser aplicados a la población objetivo, pero la situación
usual es que sólo tenemos disponible una \textbf{muestra} de esta población, a partir
de la cual queremos desarrollar predicciones o estimaciones que ayuden en la toma
de decisiones posterior.

\hypertarget{tuxe9rminos-1}{%
\subsubsection*{Términos}\label{tuxe9rminos-1}}


\begin{itemize}
\item
  \textbf{Población objetivo}: son las unidades que se pretende intervenir
  (personas, hogares, zonas geográficas, etc). Los modelos se construyen entonces
  con el fin de aplicarse a la población objetivo.
\item
  \textbf{Estructura predictiva}: se utiliza para hablar en general
  del tipo de modelos que
  se utilizan para hacer predicciones (lineales, bosques aleatorios, redes neuronales),
  las características que utiliza y cómo las utiliza el modelo (interacciones, transformaciones
  no lineales).
\item
  \textbf{Subpoblaciones de interés} o \textbf{Subpoblaciones protegidas}: subpoblaciones de la población objetivo para las cuales queremos tener evaluaciones concretas del desempeño de estimaciones o los modelos.
\item
  \textbf{Representatividad}: término alternativo a muestra probabilística bajo el caso más
  simple de muestreo autoponderado. Este es un requisito que se considera relativamente poco importante
  o relevante. Lo importante es que los datos provengan de un diseño muestral probabilístico.
\end{itemize}

Cuando tenemos una muestra, consideramos dos extremos posibles, siendo el primer extremo
el más deseable aunque no siempre alcanzable:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Muestreo probabilístico}: Los casos son seleccionados a partir de un diseño muestral probabilístico.
\item
  \textbf{Muestras naturales}: Los casos son seleccionados por un proceso natural mal o parcialmente conocido.
\end{enumerate}

Bajo el caso 1, todos las predicciones y estimaciones que se pretenden aplicar
a la población objetivo pueden ser evaluadas en cuanto
a su precisión, con \textbf{garantías probabilísticas}.
Por ejemplo, podemos dar rangos de error para estimaciones de cantidades asociadas
a toda la población objetivo, tasas de error calibradas
correctamente a la población objetivo, etc.

Bajo el caso 2, estrictamente hablando no es posible saber qué va a pasar cuando apliquemos
nuestros modelos a la población general, y no es posible construir rangos de error de
predicciones y estimaciones mediante métodos estadísticos que tengan garantías
probabilísticas.

El primer reto es entonces:

\BeginKnitrBlock{rmdnote}
\textbf{Reto: muestras naturales}

Las muestras naturales de datos pueden resultar en:

\begin{itemize}
\tightlist
\item
  Errores de estimación y de predicción incorrectamente estimados
\item
  Estructuras predictivas distintas a las que observaríamos en la población objetivo (modelos no válidos).
\item
  Extrapolaciones que no son soportadas por los datos.
\item
  Subreprensentación de subgrupos protegidos
\end{itemize}

Es decir: las cantidades y predicciones estimadas tienen error desconocido, los modelos
y características útiles en la muestra pueden no aplicar en la población objetivo, y la situación puede agravarse para grupos protegidos subrepresentados.
\EndKnitrBlock{rmdnote}

\hypertarget{ejemplo}{%
\subsubsection*{Ejemplo}\label{ejemplo}}


Supongamos que nos interesa predecir la prevalencia de anemia en niños de una población objetivo
dada. Decidimos tomar una muestra acudiendo a hospitales que ``corresponden'' a la población
objetivo para aplicar las pruebas correspondientes. La prevalencia de anemia que encontremos en esta
muestra tendrá error desconocido, posiblemente grande, como estimación de la prevalencia
en la población objetivo. Más aún, modelos de predicción construidos para esta muestra natural
no necesariamente generalizarán correctamente a la población total, y no es posible tener
una estimación confiable del error. Puede ser que la estructura predictiva
para la población objetivo sea muy distinto de la que obtenemos con nuestra muestra natural.

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: muestras naturales}

\begin{itemize}
\item
  (Cualitativa) Entender y describir las dimensiones importantes en las cuales nuestra muestra puede ser diferente a la población,
  en particular sesgos de selección no medidos. Utilizar literatura relacionada con el tema, información de expertos.
\item
  (Cuantitativa) Aunque los modelos pueden construirse con varias fuentes
  de datos, diseñadas o naturales,\\
  la validación debe llevarse a cabo idealmente con una muestra diseñada que permita
  inferencia estadística a la población objetivo. La muestra de validación debe cubrir
  apropiadamente la población objetivo y subpoblaciones protegidas.
\end{itemize}
\EndKnitrBlock{rmdtip}

\begin{itemize}
\tightlist
\item
  La construcción de la muestra de validación debe ser producida bajo un diseño muestral que permita
  inferencia a la población objetivo (\citet{lohr}).
\item
  La muestra de validación debe cubrir a subgrupos de interés y protegidos, de manera que
  sea posible hacer inferencia a sus subpoblaciones. Eso incluye tamaños de muestras adecuados según
  metodología de muestreo (ver \citet{lohr}).
\item
  Si no está disponible tal muestra, es \textbf{indispensable} un análisis de riesgos y limitaciones de
  la muestra naturales, conducida por expertos y personas que conozcan el proceso
  que generó esos datos muestrales.
\item
  Muestras \emph{representativas} no son necesarias ni en construcción de modelos ni en validación. Por ejemplo,
  en muestreo de personas muchas veces se usan esquemas de selección desconocidos, pero acotado por cuotas. Esto
  produce balance en las tasas a la que aparecen ciertos grupos,
  sin embargo, sigue siendo una
  muestra natural (en este caso a la muestra natural se le llama también \emph{de conveniencia}).
\end{itemize}

La situación ideal es la de muestreo probabilístico.
En este caso, podemos entender exactamente qué
subpoblaciones se muestrearon, a qué tasas, y cómo se relacionan estas tasas con
las tasas poblacionales. El diseño de la muestra determina nuestro alcance inferencial.

\hypertarget{muestras-y-comparaciones-predictivas}{%
\section{Muestras y comparaciones predictivas}\label{muestras-y-comparaciones-predictivas}}

En muchos casos, parte de la aplicación de un modelo de predicción se concentra
en comparaciones predictivas muy particulares. La política se aplica en función
de hallazgos del modelo en términos de las variables incluidas en el modelo.

Es necesario ser muy cuidadosos con este tipo de uso \citep{king}. Si las variables a considerar
están asignadas naturalmente por un proceso desconocido, la derivación de políticas
a partir de esos modelos puede llevar a decisiones erróneas.

En este caso, aún cuando la muestra puede permitir inferencia a la población, estamos a fin
de cuentas haciendo inferencia causal.

\BeginKnitrBlock{rmdnote}
\textbf{Reto: comparación casual}

Comparaciones predictivas o contrafactuales de algun tratamiento o variable
con datos de muestras que no tienen algún tipo de asignación aleatoria de tal tratamiento o
variable pueden ser muy lejanas de comparaciones causales al aplicar el tratamiento
en la realidad.
\EndKnitrBlock{rmdnote}

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: comparación causal}

\begin{itemize}
\item
  (Cualitativa) Entender y describir las razones por las que la variable tratamiento está
  correlacionada con variables conocidas y no conocidas.
  Describir sesgos posibles basados en análisis y conocimiento experto. Considerar qué variables
  control serían importantes para que la comparación predictiva tenga interpretación causal
\item
  (Cuantitativa) Producir datos diseñados que incluyan la consideración causal. Esto incluye
  experimentos aleatorios y otras técnicas. Esto puede hacerse antes de construir los modelos, o incluir
  gradualmente estos datos en el proceso de monitoreo y reajuste.
\end{itemize}
\EndKnitrBlock{rmdtip}

En muchos casos, suplir con modelación datos creados experimentalmente puede ser muy difícil, y los
resultados pueden depender fuertemente del decisiones del modelador, con consecuente incertidumbre rara vez medida.

\textbf{Observación}: este problema es ortogonal al de la representatividad o diseño
muestral. Muestras bien diseñadas desde el punto de vista de la población objetivo pueden
ser poco apropiadas para hacer inferencia causal, y a la inversa, datos experimentales pueden proveer indicaciones
causales correctas en la muestra seleccionada, pero tener dificultades para generalizar a una población objetivo.

\hypertarget{atributos-incompletos}{%
\section{Atributos incompletos}\label{atributos-incompletos}}

\BeginKnitrBlock{rmdnote}
\textbf{Reto: atributos faltantes o incompletos}

\begin{itemize}
\item
  Información crucial acerca de las unidades es totalmente desconocida puede resultar en
  modelos de desempeño pobre, con poca utilidad para la toma de decisiones. Comparaciones predictivas pueden ser
  poco útiles y a veces engañosas cuando existen variables omitidas importantes.
\item
  Información parcial
  completada con procesos de imputación puede producir sesgos, dependiendo de la
  razón por la que las observaciones son incompletas.
\end{itemize}
\EndKnitrBlock{rmdnote}

Muchos proyectos de aprendizaje automático están destinados a fallar por ignorar variables o atributos que
son importantes para predecir la variable objetivo. Adicionalmente, cuando existe información parcial acerca
de los atributos, generalmente la ausencia de esa información muchas veces está asociado a características relevantes
de la unidades para las que se quiere predecir.

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: atributos incompletos}

\begin{itemize}
\item
  (Cualitativa) Identificar si existen variables omitidas importantes para las cuáles no se tiene
  mediciones asociadas. Indentificar razones por las que existen datos faltantes: si la falta de datos está
  fuertemente asociada con la variable a predecir será difícil obtener buenos resultados.
\item
  (Cuantitativa) Los procesos de imputación tienen que ser evaluados en cuanto a su sensibilidad. De preferencia,
  se deben utilizar métodos de imputación múltiple que permitan evaluar incertidumbre en la imputación \citep{missingrubin}, \citep{mice}.
\end{itemize}
\EndKnitrBlock{rmdtip}

\hypertarget{retos-en-la-construcciuxf3n-y-desarrollo-de-los-modelos}{%
\chapter{Retos en la construcción y desarrollo de los modelos}\label{retos-en-la-construcciuxf3n-y-desarrollo-de-los-modelos}}

En primer lugar, consideramos el proceso usual de construcción de métodos predictivos
con aprendizaje automático \citep{ESL}, \citep{kuhn}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Preprocesamiento y limpieza de datos
\item
  Entrenamiento o ajuste de métodos de predicción
\item
  Estimación de métricas de error y selección de predictores
\item
  Validación final de predictor seleccionado
\end{enumerate}

Esto generalmente involucra al menos dos muestras (1 y 2), y de preferencia tres:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Datos de entrenamiento
\item
  Datos de validación
\item
  Datos de prueba
\end{enumerate}

\hypertarget{ausencia-de-validaciuxf3n}{%
\section{Ausencia de validación}\label{ausencia-de-validaciuxf3n}}

Uno de los primeros errores graves en este proceso es la no consideración de
etapas robustas de validación y prueba de los modelos

\BeginKnitrBlock{rmdnote}
\textbf{Reto: ausencia de muestras de validación}

Los resultados de la construcción de modelos se presentan según su desempeño
con el conjunto de datos que se usó para entrenarlos. Las métricas de desempeño, en
este caso, en general no pueden utilizarse para evaluar el verdadero comportamiento del
modelo para las nuevas muestras con las que se pretende usar.
\EndKnitrBlock{rmdnote}

Este problema de validación inexistente o pobre ocurre muchas veces con \textbf{pronósticos de series de tiempo}, donde
generalmente tenemos poca información a futuro para garantizar buen desempeño, o se trata de procesos altamente dinámicos
que son en cualquier escenario difíciles de predecir.

\BeginKnitrBlock{rmdtip}
\textbf{Medida: ausencia de muestras de validación}

\begin{itemize}
\item
  (Cuantitativa 1) Construir muestras de validación y prueba preparadas adecuadamente, como discutiremos más adelante. Esto incluye tamaño apropiado para estimar el error con precisión razonable.
\item
  (Cuantitativa 2) Existen estrategias de remuestreo o consideraciones estadísticas teóricas fundamentadas para justificar la generalización del desempeño en entrenamiento.
\end{itemize}
\EndKnitrBlock{rmdtip}

Argumentos teóricos requieren cuidado adicional, y sus supuestos deben ser evaluados.

\hypertarget{fugas-de-informaciuxf3n}{%
\section{Fugas de información}\label{fugas-de-informaciuxf3n}}

Las fugas de información \citep{kaufman} ponen en duda la validación de modelos como manera de estimar el desempeño en producción de los métodos de aprendizaje automático. Esto ocurre de dos maneras:

\begin{itemize}
\tightlist
\item
  La muestra de entrenamiento recibe \emph{fugas} de los datos de validación, lo que implica el uso de datos de validación en entrenamiento e invalida la estimación del error de predicción.
\item
  Muestras de validación y entrenamiento tienen agrupaciones temporales o de otro tipo que no se conservan en el proceso de entrenamiento y validación. En este caso, entrenamiento y validación recibe \emph{fugas} de información que no estará disponible el momento de hacer predicciones.
\end{itemize}

\BeginKnitrBlock{rmdnote}
\textbf{Reto: fugas entrenamiento validación}

Si alguna parte de los datos de validación/prueba se utiliza en la construcción de los modelos durante entrenamiento, la muestra de validación prueba no cumple su función de dar una estimación realista del error en producción.
\EndKnitrBlock{rmdnote}

\hypertarget{ejemplo-1}{%
\subsubsection*{Ejemplo}\label{ejemplo-1}}


Validación cruzada con selección de variables usando todos los datos \citep{ESL}

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: fugas entrenamiento validación}

Cualquier procesamiento y perparación de datos de entrenamiento debe evitar usar los datos de validación o prueba de ninguna manera. Se debe mantener una barrera sólida entre entrenamiento vs validación y prueba.
\EndKnitrBlock{rmdtip}

Esto incluye recodificación de datos, normalizaciones, selección de variables, identificación de datos atípicos y cualquier otro tipo de preparación de cualquier variable a ser incluida en los modelos.

El segundo tipo de filtración

\BeginKnitrBlock{rmdnote}
\textbf{Reto: fugas de datos no disponbiles en la predicción}

Algunos modelos son riesgosos de poner en producción
pues utilizan variables en entrenamiento y validación que no estarán disponibles
en la misma forma al momento de poner en producción. Esto generalmente
tiene ver con temporalidad de los datos o agrupaciones particulares.
\EndKnitrBlock{rmdnote}

\hypertarget{ejemplo-2}{%
\subsubsection*{Ejemplo}\label{ejemplo-2}}


Un modelo hace predicción de actividad criminal en distintas zonas geográficas para el
tiempo \(t\). En la extracción de datos se usa como variable de entrada el número de
unidades de policía que antendieron la zona de interés al tiempo \(t\). Esto representa una fuga en la predicción, pues al momento de predecir actividad criminal al tiempo \(t\) no
estará disponible las unidades de policía al tiempo \(t\). El modelo puede parecer preciso, pero en producción su exactitud se verá considerablemente degradada.

En el caso más extremo, aunque quizá más fácil de detectar, existen variables
presentes en datos de entrenamiento que no estarán disponibles en producción
(por ejemplo, cantidad impagada si estamos haciendo predicción de impago). \textbf{En casos
más sutiles este error puede ser difícil de detectar}.

\begin{itemize}
\tightlist
\item
  En entrenamiento: pueden existir variables acumuladas hasta el momento donde
  se registra la variable a predecir.
\item
  En producción: las variables están acumuladas hasta el momento donde se hacen
  las predicciones. La variable a predecir ocurre en el futuro.
\end{itemize}

Este tipo de error generalmente produce modelos que parecen muy optimistas,
y ocurre de muchas maneras.

\BeginKnitrBlock{rmdtip}
\textbf{Reto: fugas de datos no disponbiles en la predicción}

El esquema de validación debe \textbf{replicar tan cerca como sea posible} el esquema
bajo el cual se aplicarán las predicciones. Esto incluye que hay que replicar

\begin{itemize}
\tightlist
\item
  Ventanas temporales de observación y registro de variables y ventanas de predicción
\item
  Si existen grupos en los datos, considerar si tendremos información disponible de cada grupo cuando hacemos la predicción, o es necesario predecir para nuevos grupos.
\end{itemize}
\EndKnitrBlock{rmdtip}

\hypertarget{ejemplo-3}{%
\subsubsection*{Ejemplo}\label{ejemplo-3}}


Supongamos que queremos predecir, en varias regiones o ciudades, el daño de edificios a partir de fotos aéreas después de un temblor, usando como métrica objetivo peritajes de los edificios seleccionados. En la validación podríamos cometer el error de no respetar la agrupación regional, y el modelo podría parecer dar buenas predicciones. En la realidad, aplicaríamos para una región sobre la cual no tenemos información. La validación debe considerar la necesidad de predecir para puntos en regiones enteras sin tener información adicional de tal región (es decir, la validación debe estratificar por región).

\hypertarget{clasificaciuxf3n-probabilidades-y-clases}{%
\section{Clasificación: probabilidades y clases}\label{clasificaciuxf3n-probabilidades-y-clases}}

En muchos problemas de clasificación, por su naturaleza, es difícil acercarse
a tener certidumbre acerca de la clase de una observación según sus covariables. En
estos casos, es más útil usar probabilidades

\BeginKnitrBlock{rmdnote}
\textbf{Reto: puntos de corte arbitrario}

En problemas de clasificación, los puntos de corte o decisiones de clasificación
se toman con criterios vagamente relacionados con el contexto de la decisión
(por ejemplo, escogiendo una sensibilidad o especificidad dadas).
\EndKnitrBlock{rmdnote}

Muchas veces
se toma erróneamente un punto de corte de 1/2 para clasificación binaria, por ejemplo. Esta decisión se toma fuera del contexto de la decisión que se quiere tomar.

\BeginKnitrBlock{rmdtip}
\textbf{Medida: puntos de corte arbitrario}

\begin{itemize}
\tightlist
\item
  En problemas de clasificación ruidosos (no es posible acercarse a tener certidumbre para muchos casos), las \textbf{probabilidades de clasificación} en cada clase son instrumentos más apropiados para la toma de decisiones.
\item
  Costos y utilidades pueden utilizarse, en combinación con las probabilidades, para tomar mejores decisiones caso por caso.
\end{itemize}
\EndKnitrBlock{rmdtip}

\hypertarget{ejemplo-churn-de-clientes-evaluaciuxf3n-de-alumnos}{%
\subsubsection*{Ejemplo: churn de clientes, evaluación de alumnos}\label{ejemplo-churn-de-clientes-evaluaciuxf3n-de-alumnos}}


\hypertarget{clasificaciuxf3n-datos-desbalanceados}{%
\section{Clasificación: Datos desbalanceados}\label{clasificaciuxf3n-datos-desbalanceados}}

En problemas de clasificación muchas veces se presenta el problema de que algunas
clases tienen representación relativamente baja (por ejemplo, clases con menos de 1\% de los
casos totales). Estas clases presentan dificultades considerables en los modelos predictivos, pues puede ser que tengamos poca información acerca de esas clases y sea difícil discriminarlas existosamente de otras clases, aún cuando contemos con la información correcta.

\BeginKnitrBlock{rmdnote}
\textbf{Reto: desbalance de clases}

En datos con desbalance grande, \textbf{predictores de clase} pueden tener desempeño malo
(por ejemplo, nunca hacen predicciones de la clase minoritaria).
\EndKnitrBlock{rmdnote}

La solución es considerar las probabilidades de clase como salida principal:

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: desbalance de clases}

\begin{itemize}
\tightlist
\item
  Hacer \textbf{predicciones de probabilidad} en lugar de clase. Estas probabilidades pueden ser incorporadas al proceso de decisión posterior como tales. Evitar puntos de corte estándar de probabilidad como 0.5, o predecir según máxima probabilidad.
\item
  Cuando el número absoluto de casos minoritarios es muy chico, puede ser muy dificil encontrar información apropiada para discriminar esa clase. Se requiere \textbf{recolectar} más datos de la clase minoritaria.
\item
  Submuestrar la clase dominante (ponderando hacia arriba los casos para no perder calibración) puede ser una estrategia exitosa para reducir el tamaño de los datos y tiempo de entrenamiento.
\end{itemize}
\EndKnitrBlock{rmdtip}

\hypertarget{ejemplos-2}{%
\subsubsection*{Ejemplos}\label{ejemplos-2}}


\begin{itemize}
\item
  Consideremos que tenemos 1 millón de datos, 999 mil negativos y mil positivos. Puede ser buena idea submuestrar los negativos por una fracción dada (por ejemplo 10\%) ponderando cada caso muestreado por 10 en el ajuste y el postproceso.
\item
  Consideremos que tenemos 1 millón de datos, 999,950 mil negativos y 50 positivos. Puede ser imposible discriminar apropiadamente los 50 datos positivos. Construir conjuntos de validación empeora la situación: no es posible validar el desempeño predictivo ni construir un modelo con buen desempeño.
\end{itemize}

\hypertarget{ejemplo-ctr-en-ligas-google}{%
\subsubsection*{Ejemplo: CTR en ligas (Google)}\label{ejemplo-ctr-en-ligas-google}}


\textbf{Observaciones}:

\begin{itemize}
\tightlist
\item
  Sub y sobremuestreo alteran la proporción natural de positivos y negativos en los datos. Esto quiere decir que las probabilidades obtenidas están mal calibradas y tienen menos utilidad para la toma de decisiones.
\end{itemize}

\hypertarget{subajuste-y-sobreajuste}{%
\section{Subajuste y sobreajuste}\label{subajuste-y-sobreajuste}}

Subajuste y sobreajuste ocurren cuando la información predictiva en los datos es
usada de manera poco apropiada: en subajuste agrupamos de más y damos demasiado poco
peso a características individuales de los casos, y en subajuste les damos demasiado peso.

\hypertarget{tuxe9rminos-2}{%
\subsection*{Términos}\label{tuxe9rminos-2}}


\begin{itemize}
\item
  \textbf{Sobreajuste}: un modelo demasiado complejo para los datos disponibles tiende a capturar características no informativas como parte de la estructura predictiva. Esto se refleja muchas veces en una brecha de error grande entre entrenamiento y validación. Estos pueden ser modelos ruidosos difíciles de interpretar, y las predicciones pueden ser inestables dependiendo del conjunto de datos particular que se utilice.
\item
  \textbf{Subajuste} uno modelo demasiado simple para los datos disponibles tiende a ignorar patrones sólidos en la estructura predictiva. Esto se refleja en errores sistemáticos e identificables, por ejemplo, sub/sobre predicción sistemática para ciertos grupos o valores de las variables de entrada.
\end{itemize}

\BeginKnitrBlock{rmdnote}
\textbf{Reto: sub y sobreajuste}

\begin{itemize}
\tightlist
\item
  Modelos que presentan subajuste o sobreajuste son particularmente difíciles de interpretar, y comparaciones predictivas pueden ser malas.
\item
  Modelos subajustados pueden cometer errores sistemáticos que pueden afectar negativamente, por ejemplo, al tratamiento de grupos protegidos.
\item
  Modelos sobreajustados pueden tener predicciones inestables que cambian mucho dependiendo de los datos, por ejemplo, con cada actualización.
\end{itemize}
\EndKnitrBlock{rmdnote}

Aunque sub y sobre ajuste puede producir resultados predictivos subóptimos, pueden producir rangos de error aceptables. Sin embargo, están expuestos a los problemas señalados arriba.

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: sub y sobreajuste}

\begin{itemize}
\tightlist
\item
  Sobreajuste: debe evitarse modelos cuya brecha validación - entrenamiento sea grande (indicios de sobreajuste).
\item
  Subajuste: deben checarse subconjuntos importantes de casos (por ejemplo grupos protegidos) para verificar que no existen errores sistemáticos indeseables.
\end{itemize}
\EndKnitrBlock{rmdtip}

\hypertarget{ejemplo-reconocimiento-de-imuxe1genes}{%
\subsubsection*{Ejemplo: reconocimiento de imágenes}\label{ejemplo-reconocimiento-de-imuxe1genes}}


\hypertarget{equidad-y-desempeuxf1o-diferencial-de-predictores}{%
\section{Equidad y desempeño diferencial de predictores}\label{equidad-y-desempeuxf1o-diferencial-de-predictores}}

Métodos basados en aprendizaje automático pueden producir predicciones, que cuando no son usadas apropiadamente
en la toma de decisiones, pueden producir resultados injustos o discriminatorios (\citep{boulamwini}, \citep{barocas}, \citep{bolukbasi}).

En primer lugar establecemos que no siempre el contexto completo del problema de decisión puede enmarcarse dentro
de la parte correspondiente al \emph{aprendizaje automático}. Generalmente habrá varios objetivos de los tomadores de decisiones
que van más allá de un pronóstico dado, un sistema de clasificación, etc.

Un ejemplo es el de paridad demográfica (por ejemplo, que dos grupos de interés obtengan tasas de clasificación positiva
muy similar), que es un tipo de paridad puede ser deseable para los tomadores de decisiones, pero no necesariamente uno
que aparece naturalmente en lso métodos predictivos. De esta forma separamos dos preocupaciones importantes:

\begin{itemize}
\tightlist
\item
  Objetivos de política pública o estrategia, orientados a la justica algorítmica,
  que tienen que incorporarse en el proceso de toma de decisiones.
\item
  Fallas técnicas en los modelos que producen disparidad de resultados para grupos protegidos.
\end{itemize}

En esta parte discutiremos principalmente el segundo punto.

\hypertarget{tuxe9rminos-3}{%
\subsection{Términos}\label{tuxe9rminos-3}}

\begin{itemize}
\tightlist
\item
  \textbf{Atributo protegido}: una característica o variable \textbf{protegida} \(A\) es una para la que queremos
  que se cumplan cierto criterio de equidad en las predicciones.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

Nuestro objetivo es establecer
lineamientos para evitar que deficiencias en los modelos produzcan disparidades indeseables según los
distintos subgrupos asociados a una variable protegida \(A\) (por ejemplo, \(A\) puede ser género, raza, nivel de marginación).

Dos estrategias no muy útiles para prevenir disparidades entre los grupos de \(A\) son: \emph{ignorar} la variable \(A\) y
buscar \emph{paridad demográfica} de predicciones. En el primer caso, se pretende eliminar la posibilidad de disparidad \textbf{no} incluyendo
la variable \(G\) en el proceso de construcción de predictores. Este enfoque en pocos casos produce resultados deseables,
pues típicamente existen otros atributos asociados a \(A\) que pueden producir resultados similares aunque \(A\) no se considere.
El segundo caso, paridad demográfica de predicciones buscamos que las predicciones de los distintos grupos de \(A\) sean
similares: en el caso de clasificación, por ejemplo, que la tasa de positivos sea similar. Esto poco deseable
por sí solo: por ejemplo, si quisiéramos construir un clasificador para cierta enfermedad, consideramos que es posible que
mujeres y hombres sean afectados de manera distinta. Sin embargo, \emph{paridad demográfica} puede ser un objetivo de los tomadores
de decisiones, y eso debe tomarse en cuenta al momento de tomar la decisión asociada a la predicción.

El concepto de \textbf{equidad de posibilidades} (\citep{hardt}) es uno menos dependiente de los objetivos de los tomadores de decisiones,
y se refiere al desempeño predictivo a lo largo de distintos grupos definidos de \(A\). Si \(Y\) es la variable que queremos
predecir, y \(\hat{Y}\) es nuestra predicción, decimos que nuestra predicción satisface \textbf{equidad de posibilidades} cuando

\begin{itemize}
\tightlist
\item
  \(\hat{Y}\) y \(A\) son independientes dado el valor verdadero \(Y\)
\end{itemize}

Esto quiere decir que \(A\) no debe influir en la predicción cuando conocemos el valor verdadero \(Y\), o dicho de otra
manera: \(A\) sólo puede influir en la predicción a través de su efecto sobre \(Y\). Consideramos predictores
que se alejan mucho de este criterio son suceptibles de incluir disparidades asociadas a la variable protegida \(A\)

Una primera implicación de este criterio es:

\begin{itemize}
\tightlist
\item
  Bajo el suspuesto de equidad de posibilidades, las tasas de error predictivo sobre cada subgrupo de \(A\) son similares
\end{itemize}

En problemas de clasificación binaria, el criterio es\_

\begin{itemize}
\tightlist
\item
  En cada subgrupo, las tasas de falsos positivos y de falsos negativos son similares
\end{itemize}

\BeginKnitrBlock{rmdnote}
\textbf{Reto: inequidad algorítmica}

Aún conociendo el verdadero valor de la variable que queremos predecir, las predicciones de un método dado dependen
fuertemente de una variable protegida. En particular, las tasas de error de distintos grupos de la variable protegida
pueden ser muy distintos.
\EndKnitrBlock{rmdnote}

Esta situación de inequidad muchas veces implica que la estructura predictiva depende fuertemente o \emph{abuse} \citep{hardt}
de la información
que contiene la variable protegida \(A\) acerca de la variable respuesta, con el riesgo de producir sesgos injustos a lo largo
de distintos valores de la variable protegida.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

En el caso de clasificacón binaria, cuando una de las alternativas es \emph{deseable} para los individuos
(por ejemplo, calificar para un beneficio, crédito, candidatura de un trabajo, etc),
Un criterio menos exigente de equidad puede ser la \textbf{equidad de oportunidad}:

\begin{itemize}
\tightlist
\item
  Bajo el suspuesto de equidad de oportunidad, las tasas de falsos negativos de cada subgrupo de \(A\) son similares.
\end{itemize}

En la práctica puede considerarse cuál es más apropiado. Equidad de oportunidad muchas veces es un criterio aceptable, que
introduce criterios de justicia algorítmica permitiendo también optimizar otros resultados deseables.

\hypertarget{ejemplo-4}{%
\subsubsection*{Ejemplo}\label{ejemplo-4}}


Supongamos que queremos predecir si un potencial empleado va a durar más de 2 años en cierta compañía, y que la variable
protegida \(A\) toma dos valores (que supondremos en este caso toma dos valores: se autodenomina con religión o sin religión).
El predictor satisface \textbf{equidad de posibilidades} cuando tanto la tasa de falsos positivos como la de falsos negativos
son iguales para personas con religión y sin religión.

\BeginKnitrBlock{rmdtip}
\textbf{Medidas: inequidad algorítmica}

\begin{itemize}
\item
  Cuando existen atributos protegidos, debe evaluarse qué tanto se alejan las predicciones de la \textbf{equidad de posibilidades
  o de oportunidad}
\item
  Posprocesar adecuadamente las predicciones, si es necesario, para lograr equidad de posibilidades o oportunidad \citep{hardt}.
\item
  En el caso de clasificación, puntos de corte para distintos subgrupos pueden ajustarse para lograr equidad de oportunidad.
\end{itemize}
\EndKnitrBlock{rmdtip}

Esto en general implica que además de la decisión tomada en función de las predicciones depende de esta métrica adicional
de equidad, y no solo del análisis costo-beneficio.

\hypertarget{retos-de-uso-durante-ejecuciuxf3n}{%
\chapter{Retos de uso durante ejecución}\label{retos-de-uso-durante-ejecuciuxf3n}}

Una vez que los métodos de aprendizaje automático se comienzan utilizar para tomar decisiones, es necesario:

\begin{itemize}
\tightlist
\item
  Monitorear, en general, desempeño y características usadas en el tiempo.
\item
  Monitorear en particular resultados indeseables que pueden resultar de la interacción de usuarios con algoritmos.
\item
  Tomar decisiones acerca del proceso generador de datos para mejorar desempeño.
\end{itemize}

\hypertarget{monitoreo-de-desempeuxf1o}{%
\section{Monitoreo de desempeño}\label{monitoreo-de-desempeuxf1o}}

** Reto **
El desempeño de un modelo puede degradarse en el tiempo, debido a cambios en la población sobre la que se
hacen predicciones

** Medidas **
- (Cuantitativa) Monitorear varias métricas asociadas a las predicciones, en subgrupos definidos con antelación
(incluyendo variables protegidas).
- (Cuantitativa) Monitorear deriva en distribuciones de características con respecto al conjunto de entrenamiento.
- (Cualitativa) Cuando sea aplicable y factible, una fracción de las predicciones deberán ser examinadas por humanos y calificadas
según alguna rúbrica o mediciones de las variable que se busca predecir.

\hypertarget{retos-de-rendiciuxf3n-de-cuentas}{%
\chapter{Retos de rendición de cuentas}\label{retos-de-rendiciuxf3n-de-cuentas}}

\hypertarget{interpretabilidad-y-explicaciuxf3n-de-predicciones.}{%
\section{Interpretabilidad y explicación de predicciones.}\label{interpretabilidad-y-explicaciuxf3n-de-predicciones.}}

Es difícil dar una definición técnica de \textbf{interpretabilidad} o \textbf{explicabilidad}, que en general se refieren
a hacer inteligible para humanos el funcionamiento de un algoritmo (\citep{molnar2019}, \citep{miller}). Hay varias razones
por las que tener cierto grado de interpretabilidad en los algoritmos que se usan para tomar decisiones es importantes (\citep{molnar2019}):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Aprendizaje acerca del dominio del problema.
\item
  Aceptación social.
\item
  Detección de sesgos potenciales de los algoritmos.
\item
  Depuración y mejora de modelos.
\end{enumerate}

Los puntos 1 y 2 son más difíciles de definir, y advertimos que cualquier técnica aplicada a interpretar
los modelos con estos dos fines tienen varias dificultades que superar. El \emph{aprendizaje automático}, como se usa
tipicamente hoy en día, dificilmente se acerca a explicaciones causales o mecanísticas.

El punto 3 y 4, que veremos más abajo, son más suceptibles de análisis técnico. Los sesgos potenciales pueden ocurrir cuando en el proceso
de aprendizaje se aprenden de características que son irrelevantes, pero caracterizan a los conjuntos de entrenamiento
y validación/prueba que fueron utilizados.

Por otra parte, existe en muchos casos la necesidad de dar \textbf{explicaciones individuales} de cómo fueron tomadas ciertas decisiones
(por ejemplo, por qué a una persona no se le otorgó un crédito, o por qué alguien no califica para un programa social).

\hypertarget{interpretabilidad-sesgos-y-depuraciuxf3n}{%
\section{Interpretabilidad: sesgos y depuración}\label{interpretabilidad-sesgos-y-depuraciuxf3n}}

Sesgos potenciales pueden ocurrir cuando se usan características o variables de los datos que aunque válidos para
un momento y conjunto de datos dado, son suceptibles de cambiar fácilmente con intervenciones en el proceso generador de datos. Ejemplos
pueden ser el uso de variables que están siendo influenciadas activamente por alguna política particular que no continuará en el futuro,
o aprendizaje de características particulares de un conjunto de entrenamiento no exhaustivo (por ejemplo, en reconocimento de
imágenes reconocer especies animales por el contexto en el que se recolectó la información: zoológico, trampa cámara, etc).

\BeginKnitrBlock{rmdnote}
\textbf{Reto: sesgos potenciales y depuración}

\begin{itemize}
\item
  Algoritmos o métodos predictivos utilizan atributos poco relevantes, con validez temporal, más adelante pueden
  dañar el desempeño conforme observamos desplazamiento en datos futuros.
\item
  Algoritmos o métodos predictivos que usan una gran cantidad de atributos poco importantes tienen más riesgo de fallar
  tanto explícitamente como de forma silenciosa cuando las fuentes de datos o los procesos generadores de datos cambian.
  Ambas fallas pueden ser difíciles de diagnosticar y depurar. Fallas silenciosas representar riesgos adicionales.

  \EndKnitrBlock{rmdnote}
\end{itemize}

Este tipo de sesgo es difícil de detectar, pero principios de parsimonia y conocimiento experto pueden mitigar su riesgo:

\BeginKnitrBlock{rmdtip}
\textbf{Medidas}

\begin{itemize}
\tightlist
\item
  (Cualitativa) Incluir todas las características disponibles para construir modelos aumenta el riesgo de
  que esto suceda. Las variables a incluirse en el proceso de aprendizaje deben tener algún sustento teórico o explicación
  de por qué pueden ayudar en la tarea de predicción.
\item
  (Cuantitativa) Métodos más parsimoniosos, que usan menos características, son preferibles a modelos que utilizan
  muchas características.
\item
  (Cuantitativa) Métodos como gráficas de dependencia parcial (\citep{friedman}) o importancia basada en permutaciones (\citep{breimanrandom}, \citep{molnar2019}) pueden señalar
  variables problemáticas que reciben mucho peso en la predicción, en contra de observaciones pasadas o conocimiento experto.
\end{itemize}
\EndKnitrBlock{rmdtip}

\hypertarget{ejemplo-5}{%
\subsubsection*{Ejemplo}\label{ejemplo-5}}


\hypertarget{explicabilidad-de-predicciones-individuales}{%
\section{Explicabilidad de predicciones individuales}\label{explicabilidad-de-predicciones-individuales}}

Explicaciones individuales pueden ser importantes para rendir cuentas a usuarios o poder explicar decisiones tomadas
con aprendizaje automático\_

\BeginKnitrBlock{rmdnote}
\textbf{Reto: explicaciones individuales}
En muchos casos, es necesario dar explicaciones de por qué se tomó una decisión particular. Métodos predictivos complejos
son en principio poco transparentes en cuanto a cómo se hacen las predicciones subyacentes.
\EndKnitrBlock{rmdnote}

Existen varias formas de explicar predicciones \citep{molnar2019}. Algunas de ellas actualmente en uso y con implementaciones
robustas son:

\BeginKnitrBlock{rmdtip}
\textbf{Medida: explicaciones individuales}

Para explicar las predicciones pueden utilizarse métodos como el de explicaciones contrafactuales (\citep{wachter}),
valores de Shapley (\citep{shapley}) o gradientes integrados para redes profundas (\citep{gradient}).
Para modelos más simples (por ejemplo, lineales), pueden construirse explicaciones ad-hoc
\EndKnitrBlock{rmdtip}

\hypertarget{ejemplo-6}{%
\subsubsection*{Ejemplo}\label{ejemplo-6}}


\hypertarget{rubrica-para-aplicaciuxf3n-de-mlia-en-toma-de-decisiones}{%
\chapter{Rubrica para aplicación de ML/IA en toma de decisiones}\label{rubrica-para-aplicaciuxf3n-de-mlia-en-toma-de-decisiones}}

\backmatter
  \bibliography{referencias.bib,packages.bib}

\end{document}
